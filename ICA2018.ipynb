{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "from itertools import combinations, permutations\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gpickle(\"data/G_analysisready_03.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "performers = [x for x in G.nodes() if G.node[x]['bipartite'] == 0]\n",
    "fp = []\n",
    "\n",
    "for p in performers:\n",
    "    if 'a_pcat' in G.node[p]:\n",
    "        if G.node[p]['a_pcat'] in ['f_gay', 'f_straight']:\n",
    "            if 'unknown' not in p:\n",
    "                fp.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1: Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(fp)\n",
    "out = [('all', total, 100, 0, 0, 0)]\n",
    "out = pd.DataFrame(out, columns=['feature', 'count', '%total', '%subset', '%titles', '%titlegain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'b_ethnicity'\n",
    "p_c = Counter()\n",
    "for x in fp:\n",
    "    f = G.node[x][feature]\n",
    "    if pd.notnull(f):\n",
    "        p_c.update([feature])\n",
    "        if len(f) > 1:\n",
    "            p_c.update(['multiple'])\n",
    "        else:\n",
    "            p_c.update(f)\n",
    "        \n",
    "t_c = defaultdict(list)\n",
    "for x in fp:\n",
    "    f = G.node[x][feature]\n",
    "    if pd.notnull(f):\n",
    "        nei = G.neighbors(x)\n",
    "        t_c[feature] += list(set(nei))\n",
    "        if len(f) > 1:\n",
    "            t_c['multiple'] += list(set(nei))\n",
    "        else:\n",
    "            t_c[f[0]] += list(set(nei))\n",
    "\n",
    "thisout = []\n",
    "for k, v in p_c.most_common():\n",
    "    this = [k, v, (v/total)*100, (v/p_c[feature])*100, (len(set(t_c[k]))/len(set(t_c[feature])))*100]\n",
    "    this.append(this[-1] - this[-2])\n",
    "    thisout.append(this)\n",
    "thisout = pd.DataFrame(thisout, columns=['feature', 'count', '%total', '%subset', '%titles', '%titlegain'])\n",
    "out = pd.concat([out, thisout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'b_haircolor'\n",
    "p_c = Counter()\n",
    "for x in fp:\n",
    "    f = G.node[x][feature]\n",
    "    if pd.notnull(f):\n",
    "        p_c.update([feature])\n",
    "        if len(f) > 1:\n",
    "            p_c.update(['multiple'])\n",
    "        else:\n",
    "            p_c.update(f)\n",
    "        \n",
    "t_c = defaultdict(list)\n",
    "for x in fp:\n",
    "    f = G.node[x][feature]\n",
    "    if pd.notnull(f):\n",
    "        nei = G.neighbors(x)\n",
    "        t_c[feature] += list(set(nei))\n",
    "        if len(f) > 1:\n",
    "            t_c['multiple'] += list(set(nei))\n",
    "        else:\n",
    "            t_c[f[0]] += list(set(nei))\n",
    "\n",
    "thisout = []\n",
    "for k, v in p_c.most_common():\n",
    "    this = [k, v, (v/total)*100, (v/p_c[feature])*100, (len(set(t_c[k]))/len(set(t_c[feature])))*100]\n",
    "    this.append(this[-1] - this[-2])\n",
    "    thisout.append(this)\n",
    "thisout = pd.DataFrame(thisout, columns=['feature', 'count', '%total', '%subset', '%titles', '%titlegain'])\n",
    "out = pd.concat([out, thisout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'b_cup'\n",
    "p_c = Counter()\n",
    "for x in fp:\n",
    "    f = G.node[x][feature]\n",
    "    if pd.notnull(f):\n",
    "        p_c.update([feature])\n",
    "        p_c.update(f)\n",
    "\n",
    "t_c = defaultdict(list)\n",
    "for x in fp:\n",
    "    f = G.node[x][feature]\n",
    "    if pd.notnull(f):\n",
    "        nei = G.neighbors(x)\n",
    "        t_c[feature] += nei\n",
    "        for y in f:\n",
    "            t_c[y] += nei\n",
    "\n",
    "thisout = []\n",
    "for k, v in p_c.most_common():\n",
    "    this = [k, v, (v/total)*100, (v/p_c[feature])*100, (len(set(t_c[k]))/len(set(t_c[feature])))*100]\n",
    "    this.append(this[-1] - this[-2])\n",
    "    thisout.append(this)\n",
    "thisout = pd.DataFrame(thisout, columns=['feature', 'count', '%total', '%subset', '%titles', '%titlegain'])\n",
    "thisout = thisout.sort_values(by='feature')\n",
    "out = pd.concat([out, thisout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>count</th>\n",
       "      <th>%total</th>\n",
       "      <th>%subset</th>\n",
       "      <th>%titles</th>\n",
       "      <th>%titlegain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all</td>\n",
       "      <td>46320</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b_ethnicity</td>\n",
       "      <td>35368</td>\n",
       "      <td>76.36</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caucasian</td>\n",
       "      <td>24806</td>\n",
       "      <td>53.55</td>\n",
       "      <td>70.14</td>\n",
       "      <td>87.45</td>\n",
       "      <td>17.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black</td>\n",
       "      <td>4276</td>\n",
       "      <td>9.23</td>\n",
       "      <td>12.09</td>\n",
       "      <td>12.40</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>latin</td>\n",
       "      <td>3855</td>\n",
       "      <td>8.32</td>\n",
       "      <td>10.90</td>\n",
       "      <td>21.79</td>\n",
       "      <td>10.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asian</td>\n",
       "      <td>1720</td>\n",
       "      <td>3.71</td>\n",
       "      <td>4.86</td>\n",
       "      <td>11.38</td>\n",
       "      <td>6.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>multiple</td>\n",
       "      <td>711</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.01</td>\n",
       "      <td>13.45</td>\n",
       "      <td>11.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b_haircolor</td>\n",
       "      <td>34952</td>\n",
       "      <td>75.46</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brown</td>\n",
       "      <td>11784</td>\n",
       "      <td>25.44</td>\n",
       "      <td>33.71</td>\n",
       "      <td>62.08</td>\n",
       "      <td>28.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blond</td>\n",
       "      <td>10365</td>\n",
       "      <td>22.38</td>\n",
       "      <td>29.65</td>\n",
       "      <td>63.31</td>\n",
       "      <td>33.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>black</td>\n",
       "      <td>7313</td>\n",
       "      <td>15.79</td>\n",
       "      <td>20.92</td>\n",
       "      <td>36.35</td>\n",
       "      <td>15.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>multiple</td>\n",
       "      <td>3705</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.60</td>\n",
       "      <td>62.11</td>\n",
       "      <td>51.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>red</td>\n",
       "      <td>1785</td>\n",
       "      <td>3.85</td>\n",
       "      <td>5.11</td>\n",
       "      <td>11.41</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&gt; E</td>\n",
       "      <td>500</td>\n",
       "      <td>1.08</td>\n",
       "      <td>6.17</td>\n",
       "      <td>11.49</td>\n",
       "      <td>5.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>874</td>\n",
       "      <td>1.89</td>\n",
       "      <td>10.78</td>\n",
       "      <td>23.08</td>\n",
       "      <td>12.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>2486</td>\n",
       "      <td>5.37</td>\n",
       "      <td>30.65</td>\n",
       "      <td>56.25</td>\n",
       "      <td>25.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>1847</td>\n",
       "      <td>3.99</td>\n",
       "      <td>22.77</td>\n",
       "      <td>54.52</td>\n",
       "      <td>31.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>1394</td>\n",
       "      <td>3.01</td>\n",
       "      <td>17.19</td>\n",
       "      <td>49.59</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>1009</td>\n",
       "      <td>2.18</td>\n",
       "      <td>12.44</td>\n",
       "      <td>33.45</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b_cup</td>\n",
       "      <td>8110</td>\n",
       "      <td>17.51</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  count  %total  %subset  %titles  %titlegain\n",
       "0          all  46320  100.00     0.00     0.00        0.00\n",
       "0  b_ethnicity  35368   76.36   100.00   100.00        0.00\n",
       "1    caucasian  24806   53.55    70.14    87.45       17.31\n",
       "2        black   4276    9.23    12.09    12.40        0.31\n",
       "3        latin   3855    8.32    10.90    21.79       10.89\n",
       "4        asian   1720    3.71     4.86    11.38        6.52\n",
       "5     multiple    711    1.53     2.01    13.45       11.44\n",
       "0  b_haircolor  34952   75.46   100.00   100.00        0.00\n",
       "1        brown  11784   25.44    33.71    62.08       28.37\n",
       "2        blond  10365   22.38    29.65    63.31       33.65\n",
       "3        black   7313   15.79    20.92    36.35       15.43\n",
       "4     multiple   3705    8.00    10.60    62.11       51.51\n",
       "5          red   1785    3.85     5.11    11.41        6.30\n",
       "6          > E    500    1.08     6.17    11.49        5.32\n",
       "5            A    874    1.89    10.78    23.08       12.31\n",
       "1            B   2486    5.37    30.65    56.25       25.60\n",
       "2            C   1847    3.99    22.77    54.52       31.75\n",
       "3            D   1394    3.01    17.19    49.59       32.40\n",
       "4            E   1009    2.18    12.44    33.45       21.00\n",
       "0        b_cup   8110   17.51   100.00   100.00        0.00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accolades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in fp:\n",
    "    G.node[x]['b_awards'] = None\n",
    "    out = []\n",
    "    a = G.node[x]['awards']\n",
    "    if pd.notnull(a):\n",
    "        for v in a.values():\n",
    "            for b in v:\n",
    "                if 'Nominee' in b:\n",
    "                    out.append('nominated')\n",
    "                if 'Winner' in b:\n",
    "                    out.append('won')\n",
    "    if out:\n",
    "        G.node[x]['b_awards'] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with acc 1430 3.09\n",
      "with nom 1326 2.86\n",
      "with win 348 0.75\n"
     ]
    }
   ],
   "source": [
    "with_acc = [x for x in fp if G.node[x]['b_awards']]\n",
    "with_acc = list(set(with_acc))\n",
    "with_win = []\n",
    "for x in with_acc:\n",
    "    if 'won' in G.node[x]['b_awards']:\n",
    "        with_win.append(x)\n",
    "with_win = list(set(with_win))\n",
    "with_nom = []\n",
    "for x in with_acc:\n",
    "    if 'nominated' in G.node[x]['b_awards']:\n",
    "        with_nom.append(x)\n",
    "with_nom = list(set(with_nom))\n",
    "print(\"with acc\", len(with_acc), np.round((len(with_acc)/total)*100, 2))\n",
    "print(\"with nom\", len(with_nom), np.round((len(with_nom)/total)*100, 2))\n",
    "print(\"with win\", len(with_win), np.round((len(with_win)/total)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nom 59561\n",
      "acc 63747\n",
      "all 122269\n",
      "won 31974\n",
      "nom 48.71\n",
      "acc 52.14\n",
      "all 100.0\n",
      "won 26.15\n"
     ]
    }
   ],
   "source": [
    "t_c = defaultdict(list)\n",
    "\n",
    "for x in fp:\n",
    "    t_c['all'] += G.neighbors(x)\n",
    "    f = G.node[x]['b_awards']\n",
    "    if f:\n",
    "        nei = G.neighbors(x)\n",
    "        t_c['acc'] += nei\n",
    "        if 'nominated' in f:\n",
    "            t_c['nom'] += nei\n",
    "        if 'won' in f:\n",
    "            t_c['won'] += nei\n",
    "for k, v in t_c.items():\n",
    "    print(k, len(set(v)))\n",
    "    \n",
    "for k, v in t_c.items():\n",
    "    n = len(set(v))\n",
    "    d = len(set(t_c['all']))\n",
    "    prop = n/d\n",
    "    per = prop * 100\n",
    "    print(k, np.round(per, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2: Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc_height 9771 21.09 165.23 6.87\n",
      "proc_weight 7769 16.77 54.59 8.58\n",
      "proc_bust 8713 18.81 88.18 7.94\n",
      "proc_waist 7746 16.72 64.45 7.08\n",
      "proc_hip 7734 16.7 89.4 8.04\n"
     ]
    }
   ],
   "source": [
    "for f in ['proc_height', 'proc_weight', 'proc_bust', 'proc_waist', 'proc_hip']:\n",
    "    v = []\n",
    "    for x in fp:\n",
    "        if pd.notnull(G.node[x][f]):\n",
    "            add = G.node[x][f]\n",
    "            if f in ['proc_bust', 'proc_waist', 'proc_hip']:\n",
    "                add = add * 2.54\n",
    "            v.append(add)\n",
    "    print(f, len(v), np.round(len(v)/total*100, 2), np.round(np.mean(v), 2), np.round(np.std(v), 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 1: Title Distribution; Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we want \"exclusive\", or \"has\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(list)\n",
    "f = 'b_ethnicity'\n",
    "for x in performers:\n",
    "    deg = G.degree(x)\n",
    "    #d['performers'].append(deg)\n",
    "    if x in fp:\n",
    "        d['fp'].append(deg)\n",
    "        tf = G.node[x][f]\n",
    "        if pd.notnull(tf):\n",
    "            if len(tf) > 1:\n",
    "                d['multiple'].append(deg)\n",
    "            else:\n",
    "                d[tf[0]].append(deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/powerlaw.py:697: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (Theoretical_CDF * (1 - Theoretical_CDF))\n"
     ]
    }
   ],
   "source": [
    "fit_d = {}\n",
    "for k, v in d.items():\n",
    "    fit_d[k] = powerlaw.Fit(v, discrete=True, xmin=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.cla()\n",
    "ax = fit_d['fp'].plot_ccdf(color='k', linewidth=4, label='All')\n",
    "fit_d['caucasian'].plot_ccdf(color='b', linewidth=2, linestyle='--', ax=ax, label='Caucasian')\n",
    "fit_d['latin'].plot_ccdf(color='g', linewidth=2, linestyle='--', ax=ax, label='Latina')\n",
    "fit_d['black'].plot_ccdf(color='c', linewidth=2, linestyle='--', ax=ax, label='Black')\n",
    "fit_d['asian'].plot_ccdf(color='m', linewidth=2, linestyle='--', ax=ax, label='Asian')\n",
    "fit_d['multiple'].plot_ccdf(color='y', linewidth=2, linestyle='--', ax=ax, label='Multiple')\n",
    "ax.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(x, \",\")))\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), \",\")))\n",
    "ax.set_xlabel(r\"$x$: Number of Titles\")\n",
    "ax.set_ylabel(r\"$p(X \\geq x)$\")\n",
    "plt.legend()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6.5, 4.5)\n",
    "#plt.show()\n",
    "plt.savefig('distribution_ccdf.png', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated Power Law estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/powerlaw.py:697: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (Theoretical_CDF * (1 - Theoretical_CDF))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp 1.5008 0.0037\n",
      "caucasian 1.2772 0.0062\n",
      "black 1.4868 0.0077\n",
      "latin 1.4856 0.0049\n",
      "asian 1.5911 0.0022\n",
      "multiple 1.1845 0.004\n"
     ]
    }
   ],
   "source": [
    "l = ['fp', 'caucasian', 'black', 'latin', 'asian', 'multiple']\n",
    "\n",
    "for k in l:\n",
    "    v = fit_d[k]\n",
    "    print(k, np.round(v.truncated_power_law.parameter1, 4), np.round(v.truncated_power_law.parameter2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/powerlaw.py:697: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (Theoretical_CDF * (1 - Theoretical_CDF))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brown 1.4106 0.0061\n",
      "blond 1.3074 0.0066\n",
      "black 1.4974 0.0055\n",
      "red 1.4076 0.0103\n",
      "multiple 1.0 0.0046\n"
     ]
    }
   ],
   "source": [
    "d = defaultdict(list)\n",
    "f = 'b_haircolor'\n",
    "for x in performers:\n",
    "    deg = G.degree(x)\n",
    "    #d['performers'].append(deg)\n",
    "    if x in fp:\n",
    "        tf = G.node[x][f]\n",
    "        if pd.notnull(tf):\n",
    "            if len(tf) > 1:\n",
    "                d['multiple'].append(deg)\n",
    "            else:\n",
    "                d[tf[0]].append(deg)\n",
    "fit_d = {}\n",
    "for k, v in d.items():\n",
    "    fit_d[k] = powerlaw.Fit(v, discrete=True, xmin=1)\n",
    "l = ['brown', 'blond', 'black', 'red', 'multiple']\n",
    "\n",
    "for k in l:\n",
    "    v = fit_d[k]\n",
    "    print(k, np.round(v.truncated_power_law.parameter1, 4), np.round(v.truncated_power_law.parameter2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/powerlaw.py:697: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (Theoretical_CDF * (1 - Theoretical_CDF))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 1.016 0.0082\n",
      "B 1.0 0.0068\n",
      "C 1.0 0.0055\n",
      "D 1.0 0.0141\n",
      "E 1.0 0.0055\n",
      "> E 1.1019 0.0079\n"
     ]
    }
   ],
   "source": [
    "d = defaultdict(list)\n",
    "f = 'b_cup'\n",
    "for x in performers:\n",
    "    deg = G.degree(x)\n",
    "    #d['performers'].append(deg)\n",
    "    if x in fp:\n",
    "        tf = G.node[x][f]\n",
    "        if pd.notnull(tf):\n",
    "            d['b_cup'].append(deg)\n",
    "            d[tf[0]].append(deg)\n",
    "fit_d = {}\n",
    "for k, v in d.items():\n",
    "    fit_d[k] = powerlaw.Fit(v, discrete=True, xmin=10)\n",
    "l = ['A', 'B', 'C', 'D', 'E', '> E']\n",
    "\n",
    "for k in l:\n",
    "    v = fit_d[k]\n",
    "    print(k, np.round(v.truncated_power_law.parameter1, 4), np.round(v.truncated_power_law.parameter2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Win/Nom comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = set(with_acc)\n",
    "bottom = set(fp) - top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asian', 'black', 'caucasian', 'latin'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 'b_ethnicity'\n",
    "eths = set()\n",
    "for x in fp:\n",
    "    if pd.notnull(G.node[x][f]):\n",
    "        eths.update(G.node[x][f])\n",
    "eths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin\n",
      "[[   131.   4345.]\n",
      " [  1241.  29651.]]\n",
      "black\n",
      "[[    99.   4359.]\n",
      " [  1273.  29637.]]\n",
      "caucasian\n",
      "[[  1147.  24168.]\n",
      " [   225.   9828.]]\n",
      "asian\n",
      "[[    62.   1777.]\n",
      " [  1310.  32219.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats.contingency import margins\n",
    "\n",
    "def stdres(observed, expected):\n",
    "    n = observed.sum()\n",
    "    rsum, csum = margins(observed)\n",
    "    v = csum * rsum * (n - rsum) * (n - csum) / n**3\n",
    "    return (observed - expected) / np.sqrt(v)\n",
    "\n",
    "out = []\n",
    "\n",
    "f = 'b_ethnicity'\n",
    "eths = set()\n",
    "for x in fp:\n",
    "    if pd.notnull(G.node[x][f]):\n",
    "        eths.update(G.node[x][f])\n",
    "\n",
    "for eth in eths:\n",
    "    m = np.zeros((2, 2))\n",
    "    for x in top:\n",
    "        this = G.node[x][f]\n",
    "        if this:\n",
    "            if eth in this:\n",
    "                m[0, 0] += 1\n",
    "            else:\n",
    "                m[1, 0] += 1\n",
    "                \n",
    "    for x in bottom:\n",
    "        this = G.node[x][f]\n",
    "        if this:\n",
    "            if eth in this:\n",
    "                m[0, 1] += 1\n",
    "            else:\n",
    "                m[1, 1] += 1\n",
    "    print(eth)\n",
    "    print(m)\n",
    "    N = m.sum().sum()\n",
    "    chi2, p, dof, ex = chi2_contingency(m, correction=False)\n",
    "    phi = (m[1, 1]*m[0, 0] - m[1, 0]*m[0, 1])/np.sqrt(m[1, :].sum() * m[0, :].sum() * m[:, 0].sum() * m[:, 1].sum())\n",
    "    zm = m.copy()\n",
    "    if m[0, 0] > m[1, 0]:\n",
    "        zm = m[[1, 0]].copy()\n",
    "    pr1 = zm[0, :].sum()/zm.sum().sum()\n",
    "    pr2 = zm[1, :].sum()/zm.sum().sum()\n",
    "    pc1 = zm[:, 0].sum()/zm.sum().sum()\n",
    "    pc2 = zm[:, 1].sum()/zm.sum().sum()\n",
    "    maxphi = np.sqrt((pr1 * (1-pc2))/(pc2 * (1-pr1)))\n",
    "    if phi < 0:\n",
    "        maxphi = -maxphi\n",
    "    sr = stdres(m, ex)\n",
    "    sr = sr[0, 0]\n",
    "    oddsratio = (m[0,0]/m[0, 1])/(m[1, 0]/m[1, 1])\n",
    "    lor = np.log(oddsratio)\n",
    "    clef = (m[0,0]/m[0, :].sum()) * (m[1, 1]/m[1, :].sum())\n",
    "    out.append([eth, chi2, p, phi, maxphi, sr, oddsratio, lor, clef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p</th>\n",
       "      <th>phi</th>\n",
       "      <th>max_phi</th>\n",
       "      <th>adjusted_residual</th>\n",
       "      <th>oddsratio</th>\n",
       "      <th>logoddsratio</th>\n",
       "      <th>CLEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>latin</td>\n",
       "      <td>12.468575</td>\n",
       "      <td>4.138558e-04</td>\n",
       "      <td>-0.018776</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-3.531087</td>\n",
       "      <td>0.720359</td>\n",
       "      <td>-0.328005</td>\n",
       "      <td>0.028091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>black</td>\n",
       "      <td>37.628273</td>\n",
       "      <td>8.559479e-10</td>\n",
       "      <td>-0.032618</td>\n",
       "      <td>-0.076293</td>\n",
       "      <td>-6.134189</td>\n",
       "      <td>0.528755</td>\n",
       "      <td>-0.637231</td>\n",
       "      <td>0.021293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>caucasian</td>\n",
       "      <td>101.443488</td>\n",
       "      <td>7.353161e-24</td>\n",
       "      <td>0.053556</td>\n",
       "      <td>0.126597</td>\n",
       "      <td>10.071916</td>\n",
       "      <td>2.073029</td>\n",
       "      <td>0.729011</td>\n",
       "      <td>0.044295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asian</td>\n",
       "      <td>1.341598</td>\n",
       "      <td>2.467524e-01</td>\n",
       "      <td>-0.006159</td>\n",
       "      <td>-0.047048</td>\n",
       "      <td>-1.158274</td>\n",
       "      <td>0.858114</td>\n",
       "      <td>-0.153018</td>\n",
       "      <td>0.032397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category        chi2             p       phi   max_phi  adjusted_residual  \\\n",
       "0      latin   12.468575  4.138558e-04 -0.018776 -0.076469          -3.531087   \n",
       "1      black   37.628273  8.559479e-10 -0.032618 -0.076293          -6.134189   \n",
       "2  caucasian  101.443488  7.353161e-24  0.053556  0.126597          10.071916   \n",
       "3      asian    1.341598  2.467524e-01 -0.006159 -0.047048          -1.158274   \n",
       "\n",
       "   oddsratio  logoddsratio      CLEF  \n",
       "0   0.720359     -0.328005  0.028091  \n",
       "1   0.528755     -0.637231  0.021293  \n",
       "2   2.073029      0.729011  0.044295  \n",
       "3   0.858114     -0.153018  0.032397  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(out, columns=['category', 'chi2', 'p', 'phi', 'max_phi', 'adjusted_residual', 'oddsratio', 'logoddsratio', 'CLEF'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red\n",
      "[[   194.   2798.]\n",
      " [  1215.  30745.]]\n",
      "brown\n",
      "[[   708.  14141.]\n",
      " [   701.  19402.]]\n",
      "black\n",
      "[[   350.   8532.]\n",
      " [  1059.  25011.]]\n",
      "blond\n",
      "[[   625.  11792.]\n",
      " [   784.  21751.]]\n"
     ]
    }
   ],
   "source": [
    "f = 'b_haircolor'\n",
    "eths = set()\n",
    "for x in fp:\n",
    "    if pd.notnull(G.node[x][f]):\n",
    "        eths.update(G.node[x][f])\n",
    "eths\n",
    "\n",
    "out = []\n",
    "\n",
    "for eth in eths:\n",
    "    m = np.zeros((2, 2))\n",
    "    for x in top:\n",
    "        this = G.node[x][f]\n",
    "        if this:\n",
    "            if eth in this:\n",
    "                m[0, 0] += 1\n",
    "            else:\n",
    "                m[1, 0] += 1\n",
    "                \n",
    "    for x in bottom:\n",
    "        this = G.node[x][f]\n",
    "        if this:\n",
    "            if eth in this:\n",
    "                m[0, 1] += 1\n",
    "            else:\n",
    "                m[1, 1] += 1\n",
    "    print(eth)\n",
    "    print(m)\n",
    "    N = m.sum().sum()\n",
    "    chi2, p, dof, ex = chi2_contingency(m, correction=False)\n",
    "    phi = (m[1, 1]*m[0, 0] - m[1, 0]*m[0, 1])/np.sqrt(m[1, :].sum() * m[0, :].sum() * m[:, 0].sum() * m[:, 1].sum())\n",
    "    zm = m.copy()\n",
    "    if m[0, 0] > m[1, 0]:\n",
    "        zm = m[[1, 0]].copy()\n",
    "    pr1 = zm[0, :].sum()/zm.sum().sum()\n",
    "    pr2 = zm[1, :].sum()/zm.sum().sum()\n",
    "    pc1 = zm[:, 0].sum()/zm.sum().sum()\n",
    "    pc2 = zm[:, 1].sum()/zm.sum().sum()\n",
    "    maxphi = np.sqrt((pr1 * (1-pc2))/(pc2 * (1-pr1)))\n",
    "    if phi < 0:\n",
    "        maxphi = -maxphi\n",
    "    sr = stdres(m, ex)\n",
    "    sr = sr[0, 0]\n",
    "    oddsratio = (m[0,0]/m[0, 1])/(m[1, 0]/m[1, 1])\n",
    "    lor = np.log(oddsratio)\n",
    "    clef = (m[0,0]/m[0, :].sum()) * (m[1, 1]/m[1, :].sum())\n",
    "    out.append([eth, chi2, p, phi, maxphi, sr, oddsratio, lor, clef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>chi2</th>\n",
       "      <th>oddsratio</th>\n",
       "      <th>logoddsratio</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>50.880570</td>\n",
       "      <td>1.754495</td>\n",
       "      <td>0.562181</td>\n",
       "      <td>9.816048e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brown</td>\n",
       "      <td>36.223108</td>\n",
       "      <td>1.385740</td>\n",
       "      <td>0.326234</td>\n",
       "      <td>1.759715e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black</td>\n",
       "      <td>0.253152</td>\n",
       "      <td>0.968841</td>\n",
       "      <td>-0.031655</td>\n",
       "      <td>6.148643e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blond</td>\n",
       "      <td>49.998040</td>\n",
       "      <td>1.470468</td>\n",
       "      <td>0.385581</td>\n",
       "      <td>1.538996e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category       chi2  oddsratio  logoddsratio             p\n",
       "0      red  50.880570   1.754495      0.562181  9.816048e-13\n",
       "1    brown  36.223108   1.385740      0.326234  1.759715e-09\n",
       "2    black   0.253152   0.968841     -0.031655  6.148643e-01\n",
       "3    blond  49.998040   1.470468      0.385581  1.538996e-12"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(out, columns=['category', 'chi2', 'p', 'phi', 'max_phi', 'adjusted_residual', 'oddsratio', 'logoddsratio', 'CLEF'])\n",
    "df[['category', 'chi2', 'oddsratio', 'logoddsratio', 'p']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[  108.   766.]\n",
      " [ 1102.  6134.]]\n",
      "D\n",
      "[[  270.  1124.]\n",
      " [  940.  5776.]]\n",
      "B\n",
      "[[  329.  2157.]\n",
      " [  881.  4743.]]\n",
      "> E\n",
      "[[   77.   423.]\n",
      " [ 1133.  6477.]]\n",
      "E\n",
      "[[  150.   859.]\n",
      " [ 1060.  6041.]]\n",
      "C\n",
      "[[  276.  1571.]\n",
      " [  934.  5329.]]\n"
     ]
    }
   ],
   "source": [
    "f = 'b_cup'\n",
    "eths = set()\n",
    "for x in fp:\n",
    "    if pd.notnull(G.node[x][f]):\n",
    "        eths.update(G.node[x][f])\n",
    "eths\n",
    "\n",
    "out = []\n",
    "\n",
    "for eth in eths:\n",
    "    m = np.zeros((2, 2))\n",
    "    for x in top:\n",
    "        this = G.node[x][f]\n",
    "        if this:\n",
    "            if eth in this:\n",
    "                m[0, 0] += 1\n",
    "            else:\n",
    "                m[1, 0] += 1\n",
    "                \n",
    "    for x in bottom:\n",
    "        this = G.node[x][f]\n",
    "        if this:\n",
    "            if eth in this:\n",
    "                m[0, 1] += 1\n",
    "            else:\n",
    "                m[1, 1] += 1\n",
    "    print(eth)\n",
    "    print(m)\n",
    "    N = m.sum().sum()\n",
    "    chi2, p, dof, ex = chi2_contingency(m, correction=False)\n",
    "    phi = (m[1, 1]*m[0, 0] - m[1, 0]*m[0, 1])/np.sqrt(m[1, :].sum() * m[0, :].sum() * m[:, 0].sum() * m[:, 1].sum())\n",
    "    zm = m.copy()\n",
    "    if m[0, 0] > m[1, 0]:\n",
    "        zm = m[[1, 0]].copy()\n",
    "    pr1 = zm[0, :].sum()/zm.sum().sum()\n",
    "    pr2 = zm[1, :].sum()/zm.sum().sum()\n",
    "    pc1 = zm[:, 0].sum()/zm.sum().sum()\n",
    "    pc2 = zm[:, 1].sum()/zm.sum().sum()\n",
    "    maxphi = np.sqrt((pr1 * (1-pc2))/(pc2 * (1-pr1)))\n",
    "    if phi < 0:\n",
    "        maxphi = -maxphi\n",
    "    sr = stdres(m, ex)\n",
    "    sr = sr[0, 0]\n",
    "    oddsratio = (m[0,0]/m[0, 1])/(m[1, 0]/m[1, 1])\n",
    "    lor = np.log(oddsratio)\n",
    "    clef = (m[0,0]/m[0, :].sum()) * (m[1, 1]/m[1, :].sum())\n",
    "    out.append([eth, chi2, p, phi, maxphi, sr, oddsratio, lor, clef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>chi2</th>\n",
       "      <th>oddsratio</th>\n",
       "      <th>logoddsratio</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt; E</td>\n",
       "      <td>0.096775</td>\n",
       "      <td>1.040625</td>\n",
       "      <td>0.039822</td>\n",
       "      <td>7.557345e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>5.068682</td>\n",
       "      <td>0.784797</td>\n",
       "      <td>-0.242331</td>\n",
       "      <td>2.436190e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>8.025380</td>\n",
       "      <td>0.821151</td>\n",
       "      <td>-0.197048</td>\n",
       "      <td>4.612634e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>1.002378</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>9.744871e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>26.247009</td>\n",
       "      <td>1.476035</td>\n",
       "      <td>0.389360</td>\n",
       "      <td>3.004197e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.995179</td>\n",
       "      <td>-0.004833</td>\n",
       "      <td>9.592335e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category       chi2  oddsratio  logoddsratio             p\n",
       "3      > E   0.096775   1.040625      0.039822  7.557345e-01\n",
       "0        A   5.068682   0.784797     -0.242331  2.436190e-02\n",
       "2        B   8.025380   0.821151     -0.197048  4.612634e-03\n",
       "5        C   0.001023   1.002378      0.002376  9.744871e-01\n",
       "1        D  26.247009   1.476035      0.389360  3.004197e-07\n",
       "4        E   0.002613   0.995179     -0.004833  9.592335e-01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(out, columns=['category', 'chi2', 'p', 'phi', 'max_phi', 'adjusted_residual', 'oddsratio', 'logoddsratio', 'CLEF'])\n",
    "df[['category', 'chi2', 'oddsratio', 'logoddsratio', 'p']].sort_values(by='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 vs. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asian', 'black', 'caucasian', 'latin', 'multiple'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fset = set(['caucasian', 'black', 'latin', 'asian', 'multiple'])\n",
    "fset.add('multiple')\n",
    "fset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/scipy/stats/contingency.py:107: RuntimeWarning: invalid value encountered in true_divide\n",
      "  expected = reduce(np.multiply, margsums) / observed.sum() ** (d - 1)\n",
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n",
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/vqmalic/projects/iafd_analysis/venv/lib/python3.5/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "out=[]\n",
    "for a, b in permutations(fset, 2):\n",
    "    m = np.zeros((2, 2))\n",
    "    for x in top:\n",
    "        this = G.node[x][f]\n",
    "        if pd.notnull(this):\n",
    "            if len(this) == 1:\n",
    "                if (a, ) == this:\n",
    "                    m[0, 0] += 1\n",
    "                elif (b, ) == this:\n",
    "                    m[1, 0] += 1\n",
    "            else:\n",
    "                if a == 'multiple':\n",
    "                    m[0, 0] += 1\n",
    "                elif b == 'multiple':\n",
    "                    m[1, 0] += 1\n",
    "\n",
    "    for x in bottom:\n",
    "        this = G.node[x][f]\n",
    "        if pd.notnull(this):\n",
    "            if len(this) == 1:\n",
    "                if (a, ) == this:\n",
    "                    m[0, 1] += 1\n",
    "                elif (b, ) == this:\n",
    "                    m[1, 1] += 1\n",
    "            else:\n",
    "                if a == 'multiple':\n",
    "                    m[0, 1] += 1\n",
    "                elif b == 'multiple':\n",
    "                    m[1, 1] += 1\n",
    "    thisn = m[0, :].sum()\n",
    "    N = m.sum().sum()\n",
    "    chi2, p, dof, ex = chi2_contingency(m, correction=False)\n",
    "    phi = (m[1, 1]*m[0, 0] - m[1, 0]*m[0, 1])/np.sqrt(m[1, :].sum() * m[0, :].sum() * m[:, 0].sum() * m[:, 1].sum())\n",
    "    zm = m.copy()\n",
    "    if m[0, 0] > m[1, 0]:\n",
    "        zm = m[[1, 0]].copy()\n",
    "    pr1 = zm[0, :].sum()/zm.sum().sum()\n",
    "    pr2 = zm[1, :].sum()/zm.sum().sum()\n",
    "    pc1 = zm[:, 0].sum()/zm.sum().sum()\n",
    "    pc2 = zm[:, 1].sum()/zm.sum().sum()\n",
    "    maxphi = np.sqrt((pr1 * (1-pc2))/(pc2 * (1-pr1)))\n",
    "    if phi < 0:\n",
    "        maxphi = -maxphi\n",
    "    sr = stdres(m, ex)\n",
    "    sr = sr[0, 0]\n",
    "    oddsratio = (m[0,0]/m[0, 1])/(m[1, 0]/m[1, 1])\n",
    "    lor = np.log(oddsratio)\n",
    "    clef = (m[0,0]/m[0, :].sum()) * (m[1, 1]/m[1, :].sum())\n",
    "    out.append([(a, b), int(thisn), chi2, p, phi, maxphi, sr, oddsratio, lor, clef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp</th>\n",
       "      <th>n</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p</th>\n",
       "      <th>phi</th>\n",
       "      <th>maxphi</th>\n",
       "      <th>sr</th>\n",
       "      <th>oddsratio</th>\n",
       "      <th>lor</th>\n",
       "      <th>clef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(latin, black)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(latin, caucasian)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(latin, multiple)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(latin, asian)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(black, latin)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(black, caucasian)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(black, multiple)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(black, asian)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(caucasian, latin)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(caucasian, black)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(caucasian, multiple)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(caucasian, asian)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(multiple, latin)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(multiple, black)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(multiple, caucasian)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(multiple, asian)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(asian, latin)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(asian, black)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(asian, caucasian)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(asian, multiple)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     comp  n  chi2   p  phi  maxphi  sr  oddsratio  lor  clef\n",
       "0          (latin, black)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "1      (latin, caucasian)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "2       (latin, multiple)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "3          (latin, asian)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "4          (black, latin)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "5      (black, caucasian)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "6       (black, multiple)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "7          (black, asian)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "8      (caucasian, latin)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "9      (caucasian, black)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "10  (caucasian, multiple)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "11     (caucasian, asian)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "12      (multiple, latin)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "13      (multiple, black)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "14  (multiple, caucasian)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "15      (multiple, asian)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "16         (asian, latin)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "17         (asian, black)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "18     (asian, caucasian)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN\n",
       "19      (asian, multiple)  0   NaN NaN  NaN     NaN NaN        NaN  NaN   NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.DataFrame(out, columns=['comp', 'n', 'chi2', 'p', 'phi', 'maxphi', 'sr', 'oddsratio', 'lor', 'clef'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caucasian</th>\n",
       "      <th>black</th>\n",
       "      <th>latin</th>\n",
       "      <th>asian</th>\n",
       "      <th>multiple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>caucasian</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asian</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           caucasian  black  latin  asian  multiple\n",
       "caucasian        0.0    NaN    NaN    NaN       NaN\n",
       "black            NaN    0.0    NaN    NaN       NaN\n",
       "latin            NaN    NaN    0.0    NaN       NaN\n",
       "asian            NaN    NaN    NaN    0.0       NaN\n",
       "multiple         NaN    NaN    NaN    NaN       0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.zeros((len(fset), len(fset)))\n",
    "m = pd.DataFrame(m, columns=fset)\n",
    "m.index = fset\n",
    "for _, row in out.iterrows():\n",
    "    a, b = row['comp'][0], row['comp'][1]\n",
    "    m.loc[a, b] = row['lor']\n",
    "m = m.loc[['caucasian', 'black', 'latin', 'asian', 'multiple'], ['caucasian', 'black', 'latin', 'asian', 'multiple']]\n",
    "m.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hair color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'black', 'blond', 'brown', 'multiple', 'red'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 'b_haircolor'\n",
    "fset = set()\n",
    "for x in fp:\n",
    "    if pd.notnull(G.node[x][f]):\n",
    "        fset.update(G.node[x][f])\n",
    "fset.add('multiple')\n",
    "fset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=[]\n",
    "for a, b in permutations(fset, 2):\n",
    "    m = np.zeros((2, 2))\n",
    "    for x in top:\n",
    "        this = G.node[x][f]\n",
    "        if pd.notnull(this):\n",
    "            if len(this) == 1:\n",
    "                if (a, ) == this:\n",
    "                    m[0, 0] += 1\n",
    "                elif (b, ) == this:\n",
    "                    m[1, 0] += 1\n",
    "            else:\n",
    "                if a == 'multiple':\n",
    "                    m[0, 0] += 1\n",
    "                elif b == 'multiple':\n",
    "                    m[1, 0] += 1\n",
    "\n",
    "    for x in bottom:\n",
    "        this = G.node[x][f]\n",
    "        if pd.notnull(this):\n",
    "            if len(this) == 1:\n",
    "                if (a, ) == this:\n",
    "                    m[0, 1] += 1\n",
    "                elif (b, ) == this:\n",
    "                    m[1, 1] += 1\n",
    "            else:\n",
    "                if a == 'multiple':\n",
    "                    m[0, 1] += 1\n",
    "                elif b == 'multiple':\n",
    "                    m[1, 1] += 1\n",
    "    thisn = m[0, :].sum()\n",
    "    N = m.sum().sum()\n",
    "    chi2, p, dof, ex = chi2_contingency(m, correction=False)\n",
    "    phi = (m[1, 1]*m[0, 0] - m[1, 0]*m[0, 1])/np.sqrt(m[1, :].sum() * m[0, :].sum() * m[:, 0].sum() * m[:, 1].sum())\n",
    "    zm = m.copy()\n",
    "    if m[0, 0] > m[1, 0]:\n",
    "        zm = m[[1, 0]].copy()\n",
    "    pr1 = zm[0, :].sum()/zm.sum().sum()\n",
    "    pr2 = zm[1, :].sum()/zm.sum().sum()\n",
    "    pc1 = zm[:, 0].sum()/zm.sum().sum()\n",
    "    pc2 = zm[:, 1].sum()/zm.sum().sum()\n",
    "    maxphi = np.sqrt((pr1 * (1-pc2))/(pc2 * (1-pr1)))\n",
    "    if phi < 0:\n",
    "        maxphi = -maxphi\n",
    "    sr = stdres(m, ex)\n",
    "    sr = sr[0, 0]\n",
    "    oddsratio = (m[0,0]/m[0, 1])/(m[1, 0]/m[1, 1])\n",
    "    lor = np.log(oddsratio)\n",
    "    clef = (m[0,0]/m[0, :].sum()) * (m[1, 1]/m[1, :].sum())\n",
    "    out.append([(a, b), int(thisn), chi2, p, phi, maxphi, sr, oddsratio, lor, clef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(out, columns=['comp', 'n', 'chi2', 'p', 'phi', 'maxphi', 'sr', 'oddsratio', 'lor', 'clef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.zeros((len(fset), len(fset)))\n",
    "m = pd.DataFrame(m, columns=fset)\n",
    "m.index = fset\n",
    "for _, row in out.iterrows():\n",
    "    a, b = row['comp'][0], row['comp'][1]\n",
    "    s = np.round(row['lor'], 2)\n",
    "    s = str(s)\n",
    "    if row['p'] <= 0.0025:\n",
    "        s += \"*\"\n",
    "    m.loc[a, b] = s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brown</th>\n",
       "      <th>blond</th>\n",
       "      <th>black</th>\n",
       "      <th>red</th>\n",
       "      <th>multiple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-1.25*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blond</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45*</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-1.07*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.45*</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-1.51*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.12*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple</th>\n",
       "      <td>1.25*</td>\n",
       "      <td>1.07*</td>\n",
       "      <td>1.51*</td>\n",
       "      <td>1.12*</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          brown   blond  black    red multiple\n",
       "brown         0   -0.18   0.27  -0.13   -1.25*\n",
       "blond      0.18       0  0.45*   0.05   -1.07*\n",
       "black     -0.27  -0.45*      0  -0.39   -1.51*\n",
       "red        0.13   -0.05   0.39      0   -1.12*\n",
       "multiple  1.25*   1.07*  1.51*  1.12*        0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.loc[['brown', 'blond', 'black', 'red', 'multiple'], ['brown', 'blond', 'black', 'red', 'multiple']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'> E', 'A', 'B', 'C', 'D', 'E'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 'b_cup'\n",
    "fset = set()\n",
    "for x in fp:\n",
    "    if pd.notnull(G.node[x][f]):\n",
    "        fset.update(G.node[x][f])\n",
    "fset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=[]\n",
    "for a, b in permutations(fset, 2):\n",
    "    m = np.zeros((2, 2))\n",
    "    for x in top:\n",
    "        this = G.node[x][f]\n",
    "        if pd.notnull(this):\n",
    "            if len(this) == 1:\n",
    "                if (a, ) == this:\n",
    "                    m[0, 0] += 1\n",
    "                elif (b, ) == this:\n",
    "                    m[1, 0] += 1\n",
    "            else:\n",
    "                if a == 'multiple':\n",
    "                    m[0, 0] += 1\n",
    "                elif b == 'multiple':\n",
    "                    m[1, 0] += 1\n",
    "\n",
    "    for x in bottom:\n",
    "        this = G.node[x][f]\n",
    "        if pd.notnull(this):\n",
    "            if len(this) == 1:\n",
    "                if (a, ) == this:\n",
    "                    m[0, 1] += 1\n",
    "                elif (b, ) == this:\n",
    "                    m[1, 1] += 1\n",
    "            else:\n",
    "                if a == 'multiple':\n",
    "                    m[0, 1] += 1\n",
    "                elif b == 'multiple':\n",
    "                    m[1, 1] += 1\n",
    "    thisn = m[0, :].sum()\n",
    "    N = m.sum().sum()\n",
    "    chi2, p, dof, ex = chi2_contingency(m, correction=False)\n",
    "    phi = (m[1, 1]*m[0, 0] - m[1, 0]*m[0, 1])/np.sqrt(m[1, :].sum() * m[0, :].sum() * m[:, 0].sum() * m[:, 1].sum())\n",
    "    zm = m.copy()\n",
    "    if m[0, 0] > m[1, 0]:\n",
    "        zm = m[[1, 0]].copy()\n",
    "    pr1 = zm[0, :].sum()/zm.sum().sum()\n",
    "    pr2 = zm[1, :].sum()/zm.sum().sum()\n",
    "    pc1 = zm[:, 0].sum()/zm.sum().sum()\n",
    "    pc2 = zm[:, 1].sum()/zm.sum().sum()\n",
    "    maxphi = np.sqrt((pr1 * (1-pc2))/(pc2 * (1-pr1)))\n",
    "    if phi < 0:\n",
    "        maxphi = -maxphi\n",
    "    sr = stdres(m, ex)\n",
    "    sr = sr[0, 0]\n",
    "    oddsratio = (m[0,0]/m[0, 1])/(m[1, 0]/m[1, 1])\n",
    "    lor = np.log(oddsratio)\n",
    "    clef = (m[0,0]/m[0, :].sum()) * (m[1, 1]/m[1, :].sum())\n",
    "    out.append([(a, b), int(thisn), chi2, p, phi, maxphi, sr, oddsratio, lor, clef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp</th>\n",
       "      <th>n</th>\n",
       "      <th>chi2</th>\n",
       "      <th>p</th>\n",
       "      <th>phi</th>\n",
       "      <th>maxphi</th>\n",
       "      <th>sr</th>\n",
       "      <th>oddsratio</th>\n",
       "      <th>lor</th>\n",
       "      <th>clef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(A, D)</td>\n",
       "      <td>874</td>\n",
       "      <td>19.015849</td>\n",
       "      <td>1.296372e-05</td>\n",
       "      <td>-0.091566</td>\n",
       "      <td>-0.354111</td>\n",
       "      <td>-4.360717</td>\n",
       "      <td>0.586945</td>\n",
       "      <td>-0.532824</td>\n",
       "      <td>0.099636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(A, B)</td>\n",
       "      <td>874</td>\n",
       "      <td>0.439715</td>\n",
       "      <td>5.072601e-01</td>\n",
       "      <td>-0.011440</td>\n",
       "      <td>-0.229262</td>\n",
       "      <td>-0.663110</td>\n",
       "      <td>0.924377</td>\n",
       "      <td>-0.078635</td>\n",
       "      <td>0.107216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(A, &gt; E)</td>\n",
       "      <td>874</td>\n",
       "      <td>2.527693</td>\n",
       "      <td>1.118636e-01</td>\n",
       "      <td>-0.042891</td>\n",
       "      <td>-0.298349</td>\n",
       "      <td>-1.589872</td>\n",
       "      <td>0.774541</td>\n",
       "      <td>-0.255484</td>\n",
       "      <td>0.104540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(A, E)</td>\n",
       "      <td>874</td>\n",
       "      <td>2.493785</td>\n",
       "      <td>1.142966e-01</td>\n",
       "      <td>-0.036392</td>\n",
       "      <td>-0.370846</td>\n",
       "      <td>-1.579172</td>\n",
       "      <td>0.807415</td>\n",
       "      <td>-0.213917</td>\n",
       "      <td>0.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(A, C)</td>\n",
       "      <td>874</td>\n",
       "      <td>3.273645</td>\n",
       "      <td>7.040103e-02</td>\n",
       "      <td>-0.034686</td>\n",
       "      <td>-0.278842</td>\n",
       "      <td>-1.809322</td>\n",
       "      <td>0.802532</td>\n",
       "      <td>-0.219984</td>\n",
       "      <td>0.105105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(D, A)</td>\n",
       "      <td>1394</td>\n",
       "      <td>19.015849</td>\n",
       "      <td>1.296372e-05</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>0.354111</td>\n",
       "      <td>4.360717</td>\n",
       "      <td>1.703737</td>\n",
       "      <td>0.532824</td>\n",
       "      <td>0.169753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(D, B)</td>\n",
       "      <td>1394</td>\n",
       "      <td>25.747602</td>\n",
       "      <td>3.891103e-07</td>\n",
       "      <td>0.081462</td>\n",
       "      <td>0.319957</td>\n",
       "      <td>5.074209</td>\n",
       "      <td>1.574895</td>\n",
       "      <td>0.454189</td>\n",
       "      <td>0.168054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(D, &gt; E)</td>\n",
       "      <td>1394</td>\n",
       "      <td>3.873420</td>\n",
       "      <td>4.905647e-02</td>\n",
       "      <td>0.045223</td>\n",
       "      <td>0.283644</td>\n",
       "      <td>1.968101</td>\n",
       "      <td>1.319615</td>\n",
       "      <td>0.277340</td>\n",
       "      <td>0.163859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(D, E)</td>\n",
       "      <td>1394</td>\n",
       "      <td>8.227100</td>\n",
       "      <td>4.126941e-03</td>\n",
       "      <td>0.058512</td>\n",
       "      <td>0.391541</td>\n",
       "      <td>2.868292</td>\n",
       "      <td>1.375623</td>\n",
       "      <td>0.318907</td>\n",
       "      <td>0.164893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(D, C)</td>\n",
       "      <td>1394</td>\n",
       "      <td>11.106983</td>\n",
       "      <td>8.600327e-04</td>\n",
       "      <td>0.058541</td>\n",
       "      <td>0.391034</td>\n",
       "      <td>3.332714</td>\n",
       "      <td>1.367302</td>\n",
       "      <td>0.312840</td>\n",
       "      <td>0.164744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(B, A)</td>\n",
       "      <td>2486</td>\n",
       "      <td>0.439715</td>\n",
       "      <td>5.072601e-01</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.229262</td>\n",
       "      <td>0.663110</td>\n",
       "      <td>1.081809</td>\n",
       "      <td>0.078635</td>\n",
       "      <td>0.115988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(B, D)</td>\n",
       "      <td>2486</td>\n",
       "      <td>25.747602</td>\n",
       "      <td>3.891103e-07</td>\n",
       "      <td>-0.081462</td>\n",
       "      <td>-0.319957</td>\n",
       "      <td>-5.074209</td>\n",
       "      <td>0.634963</td>\n",
       "      <td>-0.454189</td>\n",
       "      <td>0.106708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(B, &gt; E)</td>\n",
       "      <td>2486</td>\n",
       "      <td>1.662216</td>\n",
       "      <td>1.973043e-01</td>\n",
       "      <td>-0.023594</td>\n",
       "      <td>-0.177905</td>\n",
       "      <td>-1.289270</td>\n",
       "      <td>0.837906</td>\n",
       "      <td>-0.176849</td>\n",
       "      <td>0.111961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(B, E)</td>\n",
       "      <td>2486</td>\n",
       "      <td>1.616451</td>\n",
       "      <td>2.035874e-01</td>\n",
       "      <td>-0.021506</td>\n",
       "      <td>-0.253891</td>\n",
       "      <td>-1.271397</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>-0.135282</td>\n",
       "      <td>0.112667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(B, C)</td>\n",
       "      <td>2486</td>\n",
       "      <td>2.576499</td>\n",
       "      <td>1.084613e-01</td>\n",
       "      <td>-0.024385</td>\n",
       "      <td>-0.347234</td>\n",
       "      <td>-1.605148</td>\n",
       "      <td>0.868186</td>\n",
       "      <td>-0.141349</td>\n",
       "      <td>0.112565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(&gt; E, A)</td>\n",
       "      <td>500</td>\n",
       "      <td>2.527693</td>\n",
       "      <td>1.118636e-01</td>\n",
       "      <td>0.042891</td>\n",
       "      <td>0.298349</td>\n",
       "      <td>1.589872</td>\n",
       "      <td>1.291087</td>\n",
       "      <td>0.255484</td>\n",
       "      <td>0.134970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(&gt; E, D)</td>\n",
       "      <td>500</td>\n",
       "      <td>3.873420</td>\n",
       "      <td>4.905647e-02</td>\n",
       "      <td>-0.045223</td>\n",
       "      <td>-0.283644</td>\n",
       "      <td>-1.968101</td>\n",
       "      <td>0.757797</td>\n",
       "      <td>-0.277340</td>\n",
       "      <td>0.124172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(&gt; E, B)</td>\n",
       "      <td>500</td>\n",
       "      <td>1.662216</td>\n",
       "      <td>1.973043e-01</td>\n",
       "      <td>0.023594</td>\n",
       "      <td>0.177905</td>\n",
       "      <td>1.289270</td>\n",
       "      <td>1.193451</td>\n",
       "      <td>0.176849</td>\n",
       "      <td>0.133619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(&gt; E, E)</td>\n",
       "      <td>500</td>\n",
       "      <td>0.074540</td>\n",
       "      <td>7.848383e-01</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>0.296216</td>\n",
       "      <td>0.273019</td>\n",
       "      <td>1.042443</td>\n",
       "      <td>0.041567</td>\n",
       "      <td>0.131106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(&gt; E, C)</td>\n",
       "      <td>500</td>\n",
       "      <td>0.064268</td>\n",
       "      <td>7.998730e-01</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.218915</td>\n",
       "      <td>0.253512</td>\n",
       "      <td>1.036138</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.130988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(E, A)</td>\n",
       "      <td>1009</td>\n",
       "      <td>2.493785</td>\n",
       "      <td>1.142966e-01</td>\n",
       "      <td>0.036392</td>\n",
       "      <td>0.370846</td>\n",
       "      <td>1.579172</td>\n",
       "      <td>1.238520</td>\n",
       "      <td>0.213917</td>\n",
       "      <td>0.130292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(E, D)</td>\n",
       "      <td>1009</td>\n",
       "      <td>8.227100</td>\n",
       "      <td>4.126941e-03</td>\n",
       "      <td>-0.058512</td>\n",
       "      <td>-0.391541</td>\n",
       "      <td>-2.868292</td>\n",
       "      <td>0.726943</td>\n",
       "      <td>-0.318907</td>\n",
       "      <td>0.119868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(E, B)</td>\n",
       "      <td>1009</td>\n",
       "      <td>1.616451</td>\n",
       "      <td>2.035874e-01</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>0.253891</td>\n",
       "      <td>1.271397</td>\n",
       "      <td>1.144860</td>\n",
       "      <td>0.135282</td>\n",
       "      <td>0.128988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(E, &gt; E)</td>\n",
       "      <td>1009</td>\n",
       "      <td>0.074540</td>\n",
       "      <td>7.848383e-01</td>\n",
       "      <td>-0.007028</td>\n",
       "      <td>-0.296216</td>\n",
       "      <td>-0.273019</td>\n",
       "      <td>0.959285</td>\n",
       "      <td>-0.041567</td>\n",
       "      <td>0.125768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(E, C)</td>\n",
       "      <td>1009</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>9.559992e-01</td>\n",
       "      <td>-0.001032</td>\n",
       "      <td>-0.309467</td>\n",
       "      <td>-0.055175</td>\n",
       "      <td>0.993952</td>\n",
       "      <td>-0.006067</td>\n",
       "      <td>0.126447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(C, A)</td>\n",
       "      <td>1847</td>\n",
       "      <td>3.273645</td>\n",
       "      <td>7.040103e-02</td>\n",
       "      <td>0.034686</td>\n",
       "      <td>0.278842</td>\n",
       "      <td>1.809322</td>\n",
       "      <td>1.246057</td>\n",
       "      <td>0.219984</td>\n",
       "      <td>0.130966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(C, D)</td>\n",
       "      <td>1847</td>\n",
       "      <td>11.106983</td>\n",
       "      <td>8.600327e-04</td>\n",
       "      <td>-0.058541</td>\n",
       "      <td>-0.391034</td>\n",
       "      <td>-3.332714</td>\n",
       "      <td>0.731367</td>\n",
       "      <td>-0.312840</td>\n",
       "      <td>0.120489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(C, B)</td>\n",
       "      <td>1847</td>\n",
       "      <td>2.576499</td>\n",
       "      <td>1.084613e-01</td>\n",
       "      <td>0.024385</td>\n",
       "      <td>0.347234</td>\n",
       "      <td>1.605148</td>\n",
       "      <td>1.151827</td>\n",
       "      <td>0.141349</td>\n",
       "      <td>0.129656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(C, &gt; E)</td>\n",
       "      <td>1847</td>\n",
       "      <td>0.064268</td>\n",
       "      <td>7.998730e-01</td>\n",
       "      <td>-0.005233</td>\n",
       "      <td>-0.218915</td>\n",
       "      <td>-0.253512</td>\n",
       "      <td>0.965123</td>\n",
       "      <td>-0.035500</td>\n",
       "      <td>0.126419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(C, E)</td>\n",
       "      <td>1847</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>9.559992e-01</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.309467</td>\n",
       "      <td>0.055175</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>0.006067</td>\n",
       "      <td>0.127217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        comp     n       chi2             p       phi    maxphi        sr  \\\n",
       "0     (A, D)   874  19.015849  1.296372e-05 -0.091566 -0.354111 -4.360717   \n",
       "1     (A, B)   874   0.439715  5.072601e-01 -0.011440 -0.229262 -0.663110   \n",
       "2   (A, > E)   874   2.527693  1.118636e-01 -0.042891 -0.298349 -1.589872   \n",
       "3     (A, E)   874   2.493785  1.142966e-01 -0.036392 -0.370846 -1.579172   \n",
       "4     (A, C)   874   3.273645  7.040103e-02 -0.034686 -0.278842 -1.809322   \n",
       "5     (D, A)  1394  19.015849  1.296372e-05  0.091566  0.354111  4.360717   \n",
       "6     (D, B)  1394  25.747602  3.891103e-07  0.081462  0.319957  5.074209   \n",
       "7   (D, > E)  1394   3.873420  4.905647e-02  0.045223  0.283644  1.968101   \n",
       "8     (D, E)  1394   8.227100  4.126941e-03  0.058512  0.391541  2.868292   \n",
       "9     (D, C)  1394  11.106983  8.600327e-04  0.058541  0.391034  3.332714   \n",
       "10    (B, A)  2486   0.439715  5.072601e-01  0.011440  0.229262  0.663110   \n",
       "11    (B, D)  2486  25.747602  3.891103e-07 -0.081462 -0.319957 -5.074209   \n",
       "12  (B, > E)  2486   1.662216  1.973043e-01 -0.023594 -0.177905 -1.289270   \n",
       "13    (B, E)  2486   1.616451  2.035874e-01 -0.021506 -0.253891 -1.271397   \n",
       "14    (B, C)  2486   2.576499  1.084613e-01 -0.024385 -0.347234 -1.605148   \n",
       "15  (> E, A)   500   2.527693  1.118636e-01  0.042891  0.298349  1.589872   \n",
       "16  (> E, D)   500   3.873420  4.905647e-02 -0.045223 -0.283644 -1.968101   \n",
       "17  (> E, B)   500   1.662216  1.973043e-01  0.023594  0.177905  1.289270   \n",
       "18  (> E, E)   500   0.074540  7.848383e-01  0.007028  0.296216  0.273019   \n",
       "19  (> E, C)   500   0.064268  7.998730e-01  0.005233  0.218915  0.253512   \n",
       "20    (E, A)  1009   2.493785  1.142966e-01  0.036392  0.370846  1.579172   \n",
       "21    (E, D)  1009   8.227100  4.126941e-03 -0.058512 -0.391541 -2.868292   \n",
       "22    (E, B)  1009   1.616451  2.035874e-01  0.021506  0.253891  1.271397   \n",
       "23  (E, > E)  1009   0.074540  7.848383e-01 -0.007028 -0.296216 -0.273019   \n",
       "24    (E, C)  1009   0.003044  9.559992e-01 -0.001032 -0.309467 -0.055175   \n",
       "25    (C, A)  1847   3.273645  7.040103e-02  0.034686  0.278842  1.809322   \n",
       "26    (C, D)  1847  11.106983  8.600327e-04 -0.058541 -0.391034 -3.332714   \n",
       "27    (C, B)  1847   2.576499  1.084613e-01  0.024385  0.347234  1.605148   \n",
       "28  (C, > E)  1847   0.064268  7.998730e-01 -0.005233 -0.218915 -0.253512   \n",
       "29    (C, E)  1847   0.003044  9.559992e-01  0.001032  0.309467  0.055175   \n",
       "\n",
       "    oddsratio       lor      clef  \n",
       "0    0.586945 -0.532824  0.099636  \n",
       "1    0.924377 -0.078635  0.107216  \n",
       "2    0.774541 -0.255484  0.104540  \n",
       "3    0.807415 -0.213917  0.105200  \n",
       "4    0.802532 -0.219984  0.105105  \n",
       "5    1.703737  0.532824  0.169753  \n",
       "6    1.574895  0.454189  0.168054  \n",
       "7    1.319615  0.277340  0.163859  \n",
       "8    1.375623  0.318907  0.164893  \n",
       "9    1.367302  0.312840  0.164744  \n",
       "10   1.081809  0.078635  0.115988  \n",
       "11   0.634963 -0.454189  0.106708  \n",
       "12   0.837906 -0.176849  0.111961  \n",
       "13   0.873469 -0.135282  0.112667  \n",
       "14   0.868186 -0.141349  0.112565  \n",
       "15   1.291087  0.255484  0.134970  \n",
       "16   0.757797 -0.277340  0.124172  \n",
       "17   1.193451  0.176849  0.133619  \n",
       "18   1.042443  0.041567  0.131106  \n",
       "19   1.036138  0.035500  0.130988  \n",
       "20   1.238520  0.213917  0.130292  \n",
       "21   0.726943 -0.318907  0.119868  \n",
       "22   1.144860  0.135282  0.128988  \n",
       "23   0.959285 -0.041567  0.125768  \n",
       "24   0.993952 -0.006067  0.126447  \n",
       "25   1.246057  0.219984  0.130966  \n",
       "26   0.731367 -0.312840  0.120489  \n",
       "27   1.151827  0.141349  0.129656  \n",
       "28   0.965123 -0.035500  0.126419  \n",
       "29   1.006085  0.006067  0.127217  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.DataFrame(out, columns=['comp', 'n', 'chi2', 'p', 'phi', 'maxphi', 'sr', 'oddsratio', 'lor', 'clef'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>&gt; E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt; E</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A     B     C     D     E   > E\n",
       "A    0.00 -0.08 -0.22 -0.53 -0.21 -0.26\n",
       "B    0.08  0.00 -0.14 -0.45 -0.14 -0.18\n",
       "C    0.22  0.14  0.00 -0.31  0.01 -0.04\n",
       "D    0.53  0.45  0.31  0.00  0.32  0.28\n",
       "E    0.21  0.14 -0.01 -0.32  0.00 -0.04\n",
       "> E  0.26  0.18  0.04 -0.28  0.04  0.00"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.zeros((len(fset), len(fset)))\n",
    "m = pd.DataFrame(m, columns=fset)\n",
    "m.index = fset\n",
    "for _, row in out.iterrows():\n",
    "    a, b = row['comp'][0], row['comp'][1]\n",
    "    s = np.round(row['lor'], 2)\n",
    "    m.loc[a, b] = s\n",
    "m = m.loc[['A', 'B', 'C', 'D', 'E', '> E'], ['A', 'B', 'C', 'D', 'E', '> E']]\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous, win/nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc_height 164.89 165.28 0.056\n",
      "proc_weight 53.81 54.73 0.0001\n",
      "proc_bust 86.96 88.38 0.0\n",
      "proc_waist 64.14 64.51 0.0847\n",
      "proc_hip 89.48 89.38 0.7133\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "this = top.union(bottom)\n",
    "for f in ['proc_height', 'proc_weight', 'proc_bust', 'proc_waist', 'proc_hip']:\n",
    "    t = []\n",
    "    b = []\n",
    "    for x in this:\n",
    "        if pd.notnull(G.node[x][f]):\n",
    "            add = G.node[x][f]\n",
    "            if f in ['proc_bust', 'proc_waist', 'proc_hip']:\n",
    "                add = add * 2.54\n",
    "            if x in top:\n",
    "                t.append(add)\n",
    "            elif x in bottom:\n",
    "                b.append(add)\n",
    "    print(f, np.round(np.mean(t), 2), np.round(np.mean(b), 2), np.round(ttest_ind(t, b, equal_var=False)[1], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "Okay, we can use ridge or we can use statsmodels. If we use ridge, then we'll have to bootstrap the confidence intervals. If we use statsmodels, we can use the p-values presented. \n",
    "\n",
    "First and foremost, let's simply get the data (X) prepared. We'll consider bust, waist, hip, eth, hair, cup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = ['b_ethnicity', 'b_haircolor', 'b_cup']\n",
    "\n",
    "for x in fp:\n",
    "    this = G.node[x]\n",
    "    for c in check:\n",
    "        if pd.isnull(this[c]):\n",
    "            this[c] = ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "y = []\n",
    "for x in fp:\n",
    "    data = G.node[x]\n",
    "    vec = []\n",
    "    vec.append(data['proc_bust'])\n",
    "    vec.append(data['proc_waist'])\n",
    "    vec.append(data['proc_hip'])\n",
    "    vec.append(data['proc_height'])\n",
    "    vec.append(data['proc_weight'])\n",
    "    vec.append(data['b_ethnicity'])\n",
    "    vec.append(data['b_haircolor'])\n",
    "    vec.append(data['b_cup'])\n",
    "    out.append(vec)\n",
    "    y.append(data['degree_centrality'])\n",
    "df = pd.DataFrame(out, columns=['bust', 'waist', 'hip', 'height', 'weight', 'ethnicity', 'haircolor', 'cup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "X1 = df[['bust', 'waist', 'hip', 'height', 'weight']]\n",
    "\n",
    "mlb = MultiLabelBinarizer() \n",
    "\n",
    "X2 = mlb.fit_transform(df['ethnicity'])\n",
    "ethnicity_labels = mlb.classes_\n",
    "ethnicity_labels = ['eth_'+x for x in ethnicity_labels]\n",
    "mlb = MultiLabelBinarizer() \n",
    "X3 = mlb.fit_transform(df['haircolor'])\n",
    "haircolor_labels = mlb.classes_\n",
    "haircolor_labels = ['hc_'+x for x in haircolor_labels]\n",
    "mlb = MultiLabelBinarizer() \n",
    "X4 = mlb.fit_transform(df['cup'])\n",
    "cup_labels = mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(strategy=\"mean\")\n",
    "X1 = imp.fit_transform(X1)\n",
    "X1 = pd.DataFrame(X1, columns=['bust', 'waist', 'hip', 'height', 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([X1, X2, X3, X4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X, columns = ['bust', 'waist', 'hip', 'height', 'weight'] + list(ethnicity_labels) + list(haircolor_labels) + list(cup_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.410</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.410</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1695.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 19 May 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:22:46</td>     <th>  Log-Likelihood:    </th> <td> -67539.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 46320</td>      <th>  AIC:               </th> <td>1.351e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 46300</td>      <th>  BIC:               </th> <td>1.353e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>    0.5840</td> <td>    0.289</td> <td>    2.022</td> <td> 0.043</td> <td>    0.018</td> <td>    1.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bust</th>          <td>    0.0186</td> <td>    0.004</td> <td>    4.211</td> <td> 0.000</td> <td>    0.010</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waist</th>         <td>   -0.0669</td> <td>    0.006</td> <td>  -11.525</td> <td> 0.000</td> <td>   -0.078</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hip</th>           <td>    0.0165</td> <td>    0.005</td> <td>    3.206</td> <td> 0.001</td> <td>    0.006</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>height</th>        <td>    0.0040</td> <td>    0.002</td> <td>    2.453</td> <td> 0.014</td> <td>    0.001</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>        <td>   -0.0102</td> <td>    0.002</td> <td>   -6.341</td> <td> 0.000</td> <td>   -0.013</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_asian</th>     <td>    0.0544</td> <td>    0.027</td> <td>    1.982</td> <td> 0.047</td> <td>    0.001</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_black</th>     <td>    0.1103</td> <td>    0.021</td> <td>    5.312</td> <td> 0.000</td> <td>    0.070</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_caucasian</th> <td>    0.1066</td> <td>    0.016</td> <td>    6.758</td> <td> 0.000</td> <td>    0.076</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_latin</th>     <td>   -0.0172</td> <td>    0.020</td> <td>   -0.867</td> <td> 0.386</td> <td>   -0.056</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_black</th>      <td>    0.5795</td> <td>    0.016</td> <td>   36.335</td> <td> 0.000</td> <td>    0.548</td> <td>    0.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_blond</th>      <td>    0.7171</td> <td>    0.015</td> <td>   46.320</td> <td> 0.000</td> <td>    0.687</td> <td>    0.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_brown</th>      <td>    0.6482</td> <td>    0.014</td> <td>   46.758</td> <td> 0.000</td> <td>    0.621</td> <td>    0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_red</th>        <td>    0.5593</td> <td>    0.021</td> <td>   26.502</td> <td> 0.000</td> <td>    0.518</td> <td>    0.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>> E</th>           <td>    1.3004</td> <td>    0.050</td> <td>   26.186</td> <td> 0.000</td> <td>    1.203</td> <td>    1.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A</th>             <td>    1.5172</td> <td>    0.037</td> <td>   41.494</td> <td> 0.000</td> <td>    1.446</td> <td>    1.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>             <td>    1.6691</td> <td>    0.022</td> <td>   74.693</td> <td> 0.000</td> <td>    1.625</td> <td>    1.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C</th>             <td>    1.6972</td> <td>    0.025</td> <td>   67.238</td> <td> 0.000</td> <td>    1.648</td> <td>    1.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>D</th>             <td>    1.9119</td> <td>    0.029</td> <td>   66.559</td> <td> 0.000</td> <td>    1.856</td> <td>    1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>E</th>             <td>    1.6564</td> <td>    0.034</td> <td>   49.084</td> <td> 0.000</td> <td>    1.590</td> <td>    1.723</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2771.230</td> <th>  Durbin-Watson:     </th> <td>   1.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3520.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.579</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.695</td>  <th>  Cond. No.          </th> <td>1.09e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.410\n",
       "Model:                            OLS   Adj. R-squared:                  0.410\n",
       "Method:                 Least Squares   F-statistic:                     1695.\n",
       "Date:                Sat, 19 May 2018   Prob (F-statistic):               0.00\n",
       "Time:                        10:22:46   Log-Likelihood:                -67539.\n",
       "No. Observations:               46320   AIC:                         1.351e+05\n",
       "Df Residuals:                   46300   BIC:                         1.353e+05\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const             0.5840      0.289      2.022      0.043       0.018       1.150\n",
       "bust              0.0186      0.004      4.211      0.000       0.010       0.027\n",
       "waist            -0.0669      0.006    -11.525      0.000      -0.078      -0.055\n",
       "hip               0.0165      0.005      3.206      0.001       0.006       0.027\n",
       "height            0.0040      0.002      2.453      0.014       0.001       0.007\n",
       "weight           -0.0102      0.002     -6.341      0.000      -0.013      -0.007\n",
       "eth_asian         0.0544      0.027      1.982      0.047       0.001       0.108\n",
       "eth_black         0.1103      0.021      5.312      0.000       0.070       0.151\n",
       "eth_caucasian     0.1066      0.016      6.758      0.000       0.076       0.138\n",
       "eth_latin        -0.0172      0.020     -0.867      0.386      -0.056       0.022\n",
       "hc_black          0.5795      0.016     36.335      0.000       0.548       0.611\n",
       "hc_blond          0.7171      0.015     46.320      0.000       0.687       0.747\n",
       "hc_brown          0.6482      0.014     46.758      0.000       0.621       0.675\n",
       "hc_red            0.5593      0.021     26.502      0.000       0.518       0.601\n",
       "> E               1.3004      0.050     26.186      0.000       1.203       1.398\n",
       "A                 1.5172      0.037     41.494      0.000       1.446       1.589\n",
       "B                 1.6691      0.022     74.693      0.000       1.625       1.713\n",
       "C                 1.6972      0.025     67.238      0.000       1.648       1.747\n",
       "D                 1.9119      0.029     66.559      0.000       1.856       1.968\n",
       "E                 1.6564      0.034     49.084      0.000       1.590       1.723\n",
       "==============================================================================\n",
       "Omnibus:                     2771.230   Durbin-Watson:                   1.989\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3520.949\n",
       "Skew:                           0.579   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.695   Cond. No.                     1.09e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.09e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and center the continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bust</th>\n",
       "      <th>waist</th>\n",
       "      <th>hip</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>eth_asian</th>\n",
       "      <th>eth_black</th>\n",
       "      <th>eth_caucasian</th>\n",
       "      <th>eth_latin</th>\n",
       "      <th>hc_black</th>\n",
       "      <th>hc_blond</th>\n",
       "      <th>hc_brown</th>\n",
       "      <th>hc_red</th>\n",
       "      <th>&gt; E</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.143942e-11</td>\n",
       "      <td>-1.882383e-11</td>\n",
       "      <td>-1.016556e-11</td>\n",
       "      <td>1.587221e-11</td>\n",
       "      <td>4.707025e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.143942e-11</td>\n",
       "      <td>-1.882383e-11</td>\n",
       "      <td>-1.016556e-11</td>\n",
       "      <td>1.587221e-11</td>\n",
       "      <td>4.707025e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.143942e-11</td>\n",
       "      <td>-1.882383e-11</td>\n",
       "      <td>-1.016556e-11</td>\n",
       "      <td>1.587221e-11</td>\n",
       "      <td>4.707025e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.143942e-11</td>\n",
       "      <td>-1.882383e-11</td>\n",
       "      <td>-1.016556e-11</td>\n",
       "      <td>1.587221e-11</td>\n",
       "      <td>4.707025e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.143942e-11</td>\n",
       "      <td>-1.882383e-11</td>\n",
       "      <td>-1.016556e-11</td>\n",
       "      <td>1.587221e-11</td>\n",
       "      <td>4.707025e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bust         waist           hip        height        weight  \\\n",
       "0  1.143942e-11 -1.882383e-11 -1.016556e-11  1.587221e-11  4.707025e-12   \n",
       "1  1.143942e-11 -1.882383e-11 -1.016556e-11  1.587221e-11  4.707025e-12   \n",
       "2  1.143942e-11 -1.882383e-11 -1.016556e-11  1.587221e-11  4.707025e-12   \n",
       "3  1.143942e-11 -1.882383e-11 -1.016556e-11  1.587221e-11  4.707025e-12   \n",
       "4  1.143942e-11 -1.882383e-11 -1.016556e-11  1.587221e-11  4.707025e-12   \n",
       "\n",
       "   eth_asian  eth_black  eth_caucasian  eth_latin  hc_black  hc_blond  \\\n",
       "0        0.0        0.0            0.0        1.0       1.0       0.0   \n",
       "1        0.0        0.0            1.0        0.0       0.0       0.0   \n",
       "2        0.0        0.0            1.0        0.0       0.0       1.0   \n",
       "3        0.0        0.0            1.0        0.0       0.0       0.0   \n",
       "4        0.0        0.0            1.0        1.0       1.0       0.0   \n",
       "\n",
       "   hc_brown  hc_red  > E    A    B    C    D    E  \n",
       "0       0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1       0.0     1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2       1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3       1.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4       0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X[['bust', 'waist', 'hip', 'height', 'weight']] = scaler.fit_transform(X[['bust', 'waist', 'hip', 'height', 'weight']])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.410</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.410</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1695.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 19 May 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:22:48</td>     <th>  Log-Likelihood:    </th> <td> -67539.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 46320</td>      <th>  AIC:               </th> <td>1.351e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 46300</td>      <th>  BIC:               </th> <td>1.353e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>    0.2141</td> <td>    0.010</td> <td>   21.622</td> <td> 0.000</td> <td>    0.195</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bust</th>          <td>    0.0252</td> <td>    0.006</td> <td>    4.211</td> <td> 0.000</td> <td>    0.013</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waist</th>         <td>   -0.0762</td> <td>    0.007</td> <td>  -11.525</td> <td> 0.000</td> <td>   -0.089</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hip</th>           <td>    0.0213</td> <td>    0.007</td> <td>    3.206</td> <td> 0.001</td> <td>    0.008</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>height</th>        <td>    0.0126</td> <td>    0.005</td> <td>    2.453</td> <td> 0.014</td> <td>    0.003</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>        <td>   -0.0358</td> <td>    0.006</td> <td>   -6.341</td> <td> 0.000</td> <td>   -0.047</td> <td>   -0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_asian</th>     <td>    0.0544</td> <td>    0.027</td> <td>    1.982</td> <td> 0.047</td> <td>    0.001</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_black</th>     <td>    0.1103</td> <td>    0.021</td> <td>    5.312</td> <td> 0.000</td> <td>    0.070</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_caucasian</th> <td>    0.1066</td> <td>    0.016</td> <td>    6.758</td> <td> 0.000</td> <td>    0.076</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_latin</th>     <td>   -0.0172</td> <td>    0.020</td> <td>   -0.867</td> <td> 0.386</td> <td>   -0.056</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_black</th>      <td>    0.5795</td> <td>    0.016</td> <td>   36.335</td> <td> 0.000</td> <td>    0.548</td> <td>    0.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_blond</th>      <td>    0.7171</td> <td>    0.015</td> <td>   46.320</td> <td> 0.000</td> <td>    0.687</td> <td>    0.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_brown</th>      <td>    0.6482</td> <td>    0.014</td> <td>   46.758</td> <td> 0.000</td> <td>    0.621</td> <td>    0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_red</th>        <td>    0.5593</td> <td>    0.021</td> <td>   26.502</td> <td> 0.000</td> <td>    0.518</td> <td>    0.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>> E</th>           <td>    1.3004</td> <td>    0.050</td> <td>   26.186</td> <td> 0.000</td> <td>    1.203</td> <td>    1.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A</th>             <td>    1.5172</td> <td>    0.037</td> <td>   41.494</td> <td> 0.000</td> <td>    1.446</td> <td>    1.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>             <td>    1.6691</td> <td>    0.022</td> <td>   74.693</td> <td> 0.000</td> <td>    1.625</td> <td>    1.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C</th>             <td>    1.6972</td> <td>    0.025</td> <td>   67.238</td> <td> 0.000</td> <td>    1.648</td> <td>    1.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>D</th>             <td>    1.9119</td> <td>    0.029</td> <td>   66.559</td> <td> 0.000</td> <td>    1.856</td> <td>    1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>E</th>             <td>    1.6564</td> <td>    0.034</td> <td>   49.084</td> <td> 0.000</td> <td>    1.590</td> <td>    1.723</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2771.230</td> <th>  Durbin-Watson:     </th> <td>   1.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3520.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.579</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.695</td>  <th>  Cond. No.          </th> <td>    16.0</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.410\n",
       "Model:                            OLS   Adj. R-squared:                  0.410\n",
       "Method:                 Least Squares   F-statistic:                     1695.\n",
       "Date:                Sat, 19 May 2018   Prob (F-statistic):               0.00\n",
       "Time:                        10:22:48   Log-Likelihood:                -67539.\n",
       "No. Observations:               46320   AIC:                         1.351e+05\n",
       "Df Residuals:                   46300   BIC:                         1.353e+05\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const             0.2141      0.010     21.622      0.000       0.195       0.234\n",
       "bust              0.0252      0.006      4.211      0.000       0.013       0.037\n",
       "waist            -0.0762      0.007    -11.525      0.000      -0.089      -0.063\n",
       "hip               0.0213      0.007      3.206      0.001       0.008       0.034\n",
       "height            0.0126      0.005      2.453      0.014       0.003       0.023\n",
       "weight           -0.0358      0.006     -6.341      0.000      -0.047      -0.025\n",
       "eth_asian         0.0544      0.027      1.982      0.047       0.001       0.108\n",
       "eth_black         0.1103      0.021      5.312      0.000       0.070       0.151\n",
       "eth_caucasian     0.1066      0.016      6.758      0.000       0.076       0.138\n",
       "eth_latin        -0.0172      0.020     -0.867      0.386      -0.056       0.022\n",
       "hc_black          0.5795      0.016     36.335      0.000       0.548       0.611\n",
       "hc_blond          0.7171      0.015     46.320      0.000       0.687       0.747\n",
       "hc_brown          0.6482      0.014     46.758      0.000       0.621       0.675\n",
       "hc_red            0.5593      0.021     26.502      0.000       0.518       0.601\n",
       "> E               1.3004      0.050     26.186      0.000       1.203       1.398\n",
       "A                 1.5172      0.037     41.494      0.000       1.446       1.589\n",
       "B                 1.6691      0.022     74.693      0.000       1.625       1.713\n",
       "C                 1.6972      0.025     67.238      0.000       1.648       1.747\n",
       "D                 1.9119      0.029     66.559      0.000       1.856       1.968\n",
       "E                 1.6564      0.034     49.084      0.000       1.590       1.723\n",
       "==============================================================================\n",
       "Omnibus:                     2771.230   Durbin-Watson:                   1.989\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3520.949\n",
       "Skew:                           0.579   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.695   Cond. No.                         16.0\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.115</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.115</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1504.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 19 May 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:22:49</td>     <th>  Log-Likelihood:    </th> <td> -76940.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 46320</td>      <th>  AIC:               </th> <td>1.539e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 46315</td>      <th>  BIC:               </th> <td>1.539e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>    0.3691</td> <td>    0.012</td> <td>   31.175</td> <td> 0.000</td> <td>    0.346</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_asian</th>     <td>    0.7023</td> <td>    0.032</td> <td>   22.145</td> <td> 0.000</td> <td>    0.640</td> <td>    0.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_caucasian</th> <td>    1.0935</td> <td>    0.014</td> <td>   77.437</td> <td> 0.000</td> <td>    1.066</td> <td>    1.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_black</th>     <td>    0.6662</td> <td>    0.022</td> <td>   29.961</td> <td> 0.000</td> <td>    0.623</td> <td>    0.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eth_latin</th>     <td>    0.6789</td> <td>    0.022</td> <td>   31.380</td> <td> 0.000</td> <td>    0.637</td> <td>    0.721</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>6424.721</td> <th>  Durbin-Watson:     </th> <td>   1.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>9500.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.038</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.782</td>  <th>  Cond. No.          </th> <td>    6.70</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.115\n",
       "Model:                            OLS   Adj. R-squared:                  0.115\n",
       "Method:                 Least Squares   F-statistic:                     1504.\n",
       "Date:                Sat, 19 May 2018   Prob (F-statistic):               0.00\n",
       "Time:                        10:22:49   Log-Likelihood:                -76940.\n",
       "No. Observations:               46320   AIC:                         1.539e+05\n",
       "Df Residuals:                   46315   BIC:                         1.539e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const             0.3691      0.012     31.175      0.000       0.346       0.392\n",
       "eth_asian         0.7023      0.032     22.145      0.000       0.640       0.764\n",
       "eth_caucasian     1.0935      0.014     77.437      0.000       1.066       1.121\n",
       "eth_black         0.6662      0.022     29.961      0.000       0.623       0.710\n",
       "eth_latin         0.6789      0.022     31.380      0.000       0.637       0.721\n",
       "==============================================================================\n",
       "Omnibus:                     6424.721   Durbin-Watson:                   1.988\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9500.027\n",
       "Skew:                           1.038   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.782   Cond. No.                         6.70\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsub = X[['eth_asian', 'eth_caucasian', 'eth_black', 'eth_latin']]\n",
    "#Xsub = X[['hc_black', 'hc_blond', 'hc_brown', 'hc_red']]\n",
    "#Xsub = X[['A', 'B', 'C', 'D', 'E', '> E']]\n",
    "model = sm.OLS(y, sm.add_constant(Xsub))\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.204</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.204</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2974.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 19 May 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:22:50</td>     <th>  Log-Likelihood:    </th> <td> -74474.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 46320</td>      <th>  AIC:               </th> <td>1.490e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 46315</td>      <th>  BIC:               </th> <td>1.490e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>    0.2349</td> <td>    0.010</td> <td>   23.489</td> <td> 0.000</td> <td>    0.215</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_black</th> <td>    0.9054</td> <td>    0.015</td> <td>   59.005</td> <td> 0.000</td> <td>    0.875</td> <td>    0.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_blond</th> <td>    1.1997</td> <td>    0.014</td> <td>   86.729</td> <td> 0.000</td> <td>    1.173</td> <td>    1.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_brown</th> <td>    1.0386</td> <td>    0.013</td> <td>   80.085</td> <td> 0.000</td> <td>    1.013</td> <td>    1.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hc_red</th>   <td>    0.9485</td> <td>    0.023</td> <td>   41.168</td> <td> 0.000</td> <td>    0.903</td> <td>    0.994</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>5876.229</td> <th>  Durbin-Watson:     </th> <td>   1.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8473.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.971</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.789</td>  <th>  Cond. No.          </th> <td>    4.71</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.204\n",
       "Model:                            OLS   Adj. R-squared:                  0.204\n",
       "Method:                 Least Squares   F-statistic:                     2974.\n",
       "Date:                Sat, 19 May 2018   Prob (F-statistic):               0.00\n",
       "Time:                        10:22:50   Log-Likelihood:                -74474.\n",
       "No. Observations:               46320   AIC:                         1.490e+05\n",
       "Df Residuals:                   46315   BIC:                         1.490e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.2349      0.010     23.489      0.000       0.215       0.254\n",
       "hc_black       0.9054      0.015     59.005      0.000       0.875       0.936\n",
       "hc_blond       1.1997      0.014     86.729      0.000       1.173       1.227\n",
       "hc_brown       1.0386      0.013     80.085      0.000       1.013       1.064\n",
       "hc_red         0.9485      0.023     41.168      0.000       0.903       0.994\n",
       "==============================================================================\n",
       "Omnibus:                     5876.229   Durbin-Watson:                   1.981\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8473.031\n",
       "Skew:                           0.971   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.789   Cond. No.                         4.71\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsub = X[['hc_black', 'hc_blond', 'hc_brown', 'hc_red']]\n",
    "model = sm.OLS(y, sm.add_constant(Xsub))\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.328</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.328</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3764.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 19 May 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:22:51</td>     <th>  Log-Likelihood:    </th> <td> -70570.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 46320</td>      <th>  AIC:               </th> <td>1.412e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 46313</td>      <th>  BIC:               </th> <td>1.412e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7685</td> <td>    0.006</td> <td>  135.286</td> <td> 0.000</td> <td>    0.757</td> <td>    0.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A</th>     <td>    1.9072</td> <td>    0.038</td> <td>   50.210</td> <td> 0.000</td> <td>    1.833</td> <td>    1.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>     <td>    2.0388</td> <td>    0.023</td> <td>   88.714</td> <td> 0.000</td> <td>    1.994</td> <td>    2.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C</th>     <td>    2.0615</td> <td>    0.026</td> <td>   77.930</td> <td> 0.000</td> <td>    2.010</td> <td>    2.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>D</th>     <td>    2.2640</td> <td>    0.030</td> <td>   74.778</td> <td> 0.000</td> <td>    2.205</td> <td>    2.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>E</th>     <td>    1.9921</td> <td>    0.035</td> <td>   56.253</td> <td> 0.000</td> <td>    1.923</td> <td>    2.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>> E</th>   <td>    1.5474</td> <td>    0.050</td> <td>   30.960</td> <td> 0.000</td> <td>    1.449</td> <td>    1.645</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4150.319</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5494.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.767</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.703</td>  <th>  Cond. No.          </th> <td>    9.73</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.328\n",
       "Model:                            OLS   Adj. R-squared:                  0.328\n",
       "Method:                 Least Squares   F-statistic:                     3764.\n",
       "Date:                Sat, 19 May 2018   Prob (F-statistic):               0.00\n",
       "Time:                        10:22:51   Log-Likelihood:                -70570.\n",
       "No. Observations:               46320   AIC:                         1.412e+05\n",
       "Df Residuals:                   46313   BIC:                         1.412e+05\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7685      0.006    135.286      0.000       0.757       0.780\n",
       "A              1.9072      0.038     50.210      0.000       1.833       1.982\n",
       "B              2.0388      0.023     88.714      0.000       1.994       2.084\n",
       "C              2.0615      0.026     77.930      0.000       2.010       2.113\n",
       "D              2.2640      0.030     74.778      0.000       2.205       2.323\n",
       "E              1.9921      0.035     56.253      0.000       1.923       2.062\n",
       "> E            1.5474      0.050     30.960      0.000       1.449       1.645\n",
       "==============================================================================\n",
       "Omnibus:                     4150.319   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5494.925\n",
       "Skew:                           0.767   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.703   Cond. No.                         9.73\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsub = X[['A', 'B', 'C', 'D', 'E', '> E']]\n",
    "model = sm.OLS(y, sm.add_constant(Xsub))\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=2, include_bias=False)\n",
    "Xp = pf.fit_transform(X)\n",
    "Xp = pd.DataFrame(Xp, columns= pf.get_feature_names(X.columns) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> E A\n",
      "> E B\n",
      "> E C\n",
      "> E D\n",
      "> E E\n",
      "A B\n",
      "A C\n",
      "A D\n",
      "A E\n",
      "B C\n",
      "B D\n",
      "B E\n",
      "C D\n",
      "C E\n",
      "D E\n"
     ]
    }
   ],
   "source": [
    "drop = []\n",
    "for column in Xp.columns:\n",
    "    if Xp[column].sum() == 0:\n",
    "        print(column)\n",
    "        drop.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp = Xp.drop(drop, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39565348681428858"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = Lasso(alpha=1e-2, max_iter=20000)\n",
    "lr.fit(Xp, y)\n",
    "lr.score(Xp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "colset = ['only', 'height', 'weight', 'bust', 'waist', 'hip', 'eth_caucasian', 'eth_black', 'eth_latin', 'eth_asian', 'hc_black', 'hc_brown', 'hc_blond', 'hc_red', 'A', 'B', 'C', 'D', 'E', '>_E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(0, index=colset, columns=colset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, coef in zip(Xp.columns, lr.coef_):\n",
    "    feature = feature.replace(\"> E\", \">_E\")\n",
    "    if \" \" in feature:\n",
    "        a, b = feature.split(\" \")\n",
    "        coefs.loc[a, b] = coef\n",
    "        coefs.loc[b, a] = coef\n",
    "    elif \"^\" in feature:\n",
    "        a, b = feature.split(\"^\")\n",
    "        coefs.loc[a, a] = coef\n",
    "    else:\n",
    "        coefs.loc[feature, 'only'] = coef\n",
    "        coefs.loc['only', feature] = coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>only</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bust</th>\n",
       "      <th>waist</th>\n",
       "      <th>hip</th>\n",
       "      <th>eth_caucasian</th>\n",
       "      <th>eth_black</th>\n",
       "      <th>eth_latin</th>\n",
       "      <th>eth_asian</th>\n",
       "      <th>hc_black</th>\n",
       "      <th>hc_brown</th>\n",
       "      <th>hc_blond</th>\n",
       "      <th>hc_red</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>&gt;_E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>only</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bust</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waist</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hip</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eth_caucasian</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eth_black</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eth_latin</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eth_asian</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_black</th>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_brown</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_blond</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hc_red</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>1.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;_E</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               only  height  weight  bust  waist   hip  eth_caucasian  \\\n",
       "only           0.00    0.00   -0.00  0.00  -0.13  0.00           0.10   \n",
       "height         0.00    0.04    0.00 -0.00   0.00  0.00           0.03   \n",
       "weight        -0.00    0.00    0.00  0.00  -0.00  0.01          -0.06   \n",
       "bust           0.00   -0.00    0.00  0.00  -0.01 -0.00           0.00   \n",
       "waist         -0.13    0.00   -0.00 -0.01   0.03 -0.02          -0.00   \n",
       "hip            0.00    0.00    0.01 -0.00  -0.02  0.01           0.00   \n",
       "eth_caucasian  0.10    0.03   -0.06  0.00  -0.00  0.00           0.02   \n",
       "eth_black      0.00    0.00    0.00  0.00  -0.00  0.00           0.00   \n",
       "eth_latin      0.00   -0.00   -0.00 -0.00  -0.00 -0.00           0.00   \n",
       "eth_asian      0.00   -0.00   -0.00 -0.00  -0.00 -0.00           0.00   \n",
       "hc_black       0.26   -0.00   -0.00 -0.00  -0.00  0.00           0.00   \n",
       "hc_brown       0.53    0.00   -0.00 -0.00  -0.00  0.00           0.07   \n",
       "hc_blond       0.54    0.00   -0.00  0.00  -0.00  0.00           0.11   \n",
       "hc_red         0.39    0.00    0.00  0.00   0.00  0.00           0.00   \n",
       "A              0.59   -0.00   -0.00 -0.00  -0.00 -0.00           0.00   \n",
       "B              1.15    0.00   -0.00  0.00   0.00  0.00           0.00   \n",
       "C              1.13    0.00   -0.00 -0.00  -0.00 -0.00           0.00   \n",
       "D              1.28    0.00   -0.00  0.00   0.00  0.00           0.00   \n",
       "E              0.89    0.00   -0.00 -0.00  -0.00 -0.00           0.00   \n",
       ">_E            0.00    0.00    0.02  0.02   0.00  0.00           0.00   \n",
       "\n",
       "               eth_black  eth_latin  eth_asian  hc_black  hc_brown  hc_blond  \\\n",
       "only                 0.0        0.0        0.0      0.26      0.53      0.54   \n",
       "height               0.0       -0.0       -0.0     -0.00      0.00      0.00   \n",
       "weight               0.0       -0.0       -0.0     -0.00     -0.00     -0.00   \n",
       "bust                 0.0       -0.0       -0.0     -0.00     -0.00      0.00   \n",
       "waist               -0.0       -0.0       -0.0     -0.00     -0.00     -0.00   \n",
       "hip                  0.0       -0.0       -0.0      0.00      0.00      0.00   \n",
       "eth_caucasian        0.0        0.0        0.0      0.00      0.07      0.11   \n",
       "eth_black            0.0       -0.0        0.0      0.00      0.00     -0.00   \n",
       "eth_latin           -0.0        0.0        0.0      0.00      0.00      0.00   \n",
       "eth_asian            0.0        0.0        0.0      0.00      0.00      0.00   \n",
       "hc_black             0.0        0.0        0.0      0.26      0.06      0.00   \n",
       "hc_brown             0.0        0.0        0.0      0.06      0.00      0.13   \n",
       "hc_blond            -0.0        0.0        0.0      0.00      0.13      0.00   \n",
       "hc_red               0.0        0.0        0.0      0.00      0.00      0.00   \n",
       "A                    0.0        0.0        0.0      0.00      0.00      0.00   \n",
       "B                    0.0        0.0        0.0      0.00      0.00      0.00   \n",
       "C                    0.0        0.0        0.0      0.00      0.00      0.00   \n",
       "D                    0.0        0.0        0.0      0.00      0.00      0.00   \n",
       "E                    0.0        0.0        0.0      0.00      0.00      0.00   \n",
       ">_E                  0.0        0.0        0.0      0.00      0.00      0.00   \n",
       "\n",
       "               hc_red     A     B     C     D     E   >_E  \n",
       "only             0.39  0.59  1.15  1.13  1.28  0.89  0.00  \n",
       "height           0.00 -0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "weight           0.00 -0.00 -0.00 -0.00 -0.00 -0.00  0.02  \n",
       "bust             0.00 -0.00  0.00 -0.00  0.00 -0.00  0.02  \n",
       "waist            0.00 -0.00  0.00 -0.00  0.00 -0.00  0.00  \n",
       "hip              0.00 -0.00  0.00 -0.00  0.00 -0.00  0.00  \n",
       "eth_caucasian    0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "eth_black        0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "eth_latin        0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "eth_asian        0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "hc_black         0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "hc_brown         0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "hc_blond         0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "hc_red           0.01  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "A                0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "B                0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "C                0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "D                0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "E                0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       ">_E              0.00  0.00  0.00  0.00  0.00  0.00  0.00  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(coefs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "from numpy import ma\n",
    "\n",
    "class MidPointNorm(Normalize):    \n",
    "    def __init__(self, midpoint=0, vmin=None, vmax=None, clip=False):\n",
    "        Normalize.__init__(self,vmin, vmax, clip)\n",
    "        self.midpoint = midpoint\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        if clip is None:\n",
    "            clip = self.clip\n",
    "\n",
    "        result, is_scalar = self.process_value(value)\n",
    "\n",
    "        self.autoscale_None(result)\n",
    "        vmin, vmax, midpoint = self.vmin, self.vmax, self.midpoint\n",
    "\n",
    "        if not (vmin < midpoint < vmax):\n",
    "            raise ValueError(\"midpoint must be between maxvalue and minvalue.\")       \n",
    "        elif vmin == vmax:\n",
    "            result.fill(0) # Or should it be all masked? Or 0.5?\n",
    "        elif vmin > vmax:\n",
    "            raise ValueError(\"maxvalue must be bigger than minvalue\")\n",
    "        else:\n",
    "            vmin = float(vmin)\n",
    "            vmax = float(vmax)\n",
    "            if clip:\n",
    "                mask = ma.getmask(result)\n",
    "                result = ma.array(np.clip(result.filled(vmax), vmin, vmax),\n",
    "                                  mask=mask)\n",
    "\n",
    "            # ma division is very slow; we can take a shortcut\n",
    "            resdat = result.data\n",
    "\n",
    "            #First scale to -1 to 1 range, than to from 0 to 1.\n",
    "            resdat -= midpoint            \n",
    "            resdat[resdat>0] /= abs(vmax - midpoint)            \n",
    "            resdat[resdat<0] /= abs(vmin - midpoint)\n",
    "\n",
    "            resdat /= 2.\n",
    "            resdat += 0.5\n",
    "            result = ma.array(resdat, mask=result.mask, copy=False)                \n",
    "\n",
    "        if is_scalar:\n",
    "            result = result[0]            \n",
    "        return result\n",
    "\n",
    "    def inverse(self, value):\n",
    "        if not self.scaled():\n",
    "            raise ValueError(\"Not invertible until scaled\")\n",
    "        vmin, vmax, midpoint = self.vmin, self.vmax, self.midpoint\n",
    "\n",
    "        if cbook.iterable(value):\n",
    "            val = ma.asarray(value)\n",
    "            val = 2 * (val-0.5)  \n",
    "            val[val>0]  *= abs(vmax - midpoint)\n",
    "            val[val<0] *= abs(vmin - midpoint)\n",
    "            val += midpoint\n",
    "            return val\n",
    "        else:\n",
    "            val = 2 * (val - 0.5)\n",
    "            if val < 0: \n",
    "                return  val*abs(vmin-midpoint) + midpoint\n",
    "            else:\n",
    "                return  val*abs(vmax-midpoint) + midpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAD7CAYAAACMu+pyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyv8BptuA15QKyZsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2c3c41f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm = MidPointNorm(midpoint=0)\n",
    "\n",
    "plt.imshow(coefs, cmap='seismic', norm=norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(Lasso(alpha=1e-3), Xp, y, scoring='r2', cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.415715432622\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Lasso(alpha=1e-3, max_iter=20000)\n",
    "lr.fit(Xp, y)\n",
    "y_pred = lr.predict(Xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD7CAYAAABOi672AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2c602ab70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y, y_pred, 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
